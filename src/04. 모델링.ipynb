{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sklearn.model\n",
    "# %pip install xgboost\n",
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "## 1. 패키지 import\n",
    "############################################################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from pickle import dump, load\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# User Package\n",
    "from module.logger import log_message\n",
    "from module.func_mdl_prfmnc import func_mdl_prfmnc\n",
    "import module.sqlTransaction as sqlT\n",
    "import importlib\n",
    "importlib.reload(sqlT)\n",
    "\n",
    "############################################################################################################\n",
    "## 2. 초기설정\n",
    "############################################################################################################\n",
    "# 경로설정\n",
    "dir_work = f'c:/Users/user/OneDrive - 파인트리파트너스(주)/movie'\n",
    "dir_func = f'{dir_work}/src/module'\n",
    "dir_data = f'{dir_work}/data'\n",
    "dir_mdl  = f'{dir_work}/data/trn'\n",
    "dir_prd  = f'{dir_work}/data/prd'\n",
    "# DB연결\n",
    "conn = sqlite3.connect(f\"{dir_data}/pine_movie.db\", isolation_level=None)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 함수 호출\n",
    "# exec(open(f\"{dir_func}/sqlTransaction.py\"      , encoding= 'utf-8').read() )\n",
    "# exec(open(f\"{dir_func}/logger.py\"              , encoding= 'utf-8').read() )\n",
    "exec(open(f\"{dir_func}/func_mdl_iv_woe.py\"              , encoding= 'utf-8').read() )\n",
    "\n",
    "############################################################################################################\n",
    "## 3. 파라미터 추출\n",
    "############################################################################################################\n",
    "# 입력 파라미터 추출\n",
    "try :\n",
    "    bas_ym = sys.argv[1]\n",
    "    if not bas_ym.isdigit() : raise\n",
    "except:\n",
    "    bas_ym = '201206'\n",
    "    \n",
    "list_bas_ym   = [datetime.strftime(datetime.strptime(bas_ym, '%Y%m') - relativedelta(months = (i) ), '%Y%m') for i in range(3)]\n",
    "bas_ym_aft_1m = datetime.strftime(datetime.strptime(bas_ym, '%Y%m') + relativedelta(months = 1 ), '%Y%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력데이터 준비\n",
    "#### 타겟마트 기반 층화추출 방식의 샘플링 - 피쳐마트 결합  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 학습 준비 : 샘플링배수 = 1, 건수 = 1755\n",
      "[LOG] 학습 준비 : 샘플링배수 = 2, 건수 = 1755\n",
      "[LOG] 학습 준비 : 샘플링배수 = 1, 건수 = 1720\n",
      "[LOG] 학습 준비 : 샘플링배수 = 2, 건수 = 1720\n",
      "[LOG] 학습 준비 : 샘플링배수 = 1, 건수 = 1766\n",
      "[LOG] 학습 준비 : 샘플링배수 = 2, 건수 = 1766\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# 1. 샘플링\n",
    "#######################################################################################\n",
    "# 타겟마트 로드\n",
    "df_smpl_base = pd.read_sql(f\"\"\"\n",
    "    SELECT\n",
    "          T1.기준년월 \n",
    "        , T1.회원번호\n",
    "        , CASE WHEN 성별 = 'Male'                                           THEN 0  -- 남자\n",
    "               WHEN 성별 = 'Female'                                         THEN 1  -- 여자\n",
    "          END                                                                                   AS 성별\n",
    "        , CASE WHEN 나이 <  20                                              THEN 1\n",
    "               WHEN 나이 <  30 AND 나이 >= 20                               THEN 2\n",
    "               WHEN 나이 <  40 AND 나이 >= 30                               THEN 3\n",
    "               WHEN 나이 <  50 AND 나이 >= 40                               THEN 4\n",
    "               WHEN 나이 <  60 AND 나이 >= 50                               THEN 5\n",
    "               WHEN 나이 <  70 AND 나이 >= 60                               THEN 6\n",
    "               WHEN 나이 <  80 AND 나이 >= 70                               THEN 7\n",
    "               WHEN 나이 >= 80                                              THEN 8\n",
    "          END                                                                                  AS 연령대\n",
    "        , T1.공포_타겟\n",
    "    FROM TARGET_MART T1\n",
    "    \n",
    "    LEFT JOIN CUSTOMER T2\n",
    "    ON T1.회원번호 = T2.회원번호\n",
    "    \n",
    "    WHERE T1.기준년월 BETWEEN {min(list_bas_ym)} and {max(list_bas_ym)}\n",
    "\"\"\", conn)\n",
    "\n",
    "list_df_smpl = []\n",
    "for i_bas_ym in list_bas_ym :\n",
    "    for i_smpl_rt in [1,2] :\n",
    "        \n",
    "        # 기준년월별 샘플링 별도 수행 후 통합 방식으로 진행\n",
    "        df_smpl_tmp_1 = df_smpl_base[df_smpl_base['기준년월'] == int(i_bas_ym)]\n",
    "        print(f'[LOG] 학습 준비 : 샘플링배수 = {i_smpl_rt}, 건수 = {len(df_smpl_tmp_1)}')\n",
    "        \n",
    "        v_cnt_event     = len(df_smpl_tmp_1[df_smpl_tmp_1['공포_타겟'] == 1])\n",
    "        v_cnt_non_event = len(df_smpl_tmp_1[df_smpl_tmp_1['공포_타겟'] == 0])\n",
    "        event_rt = v_cnt_event / v_cnt_non_event\n",
    "        \n",
    "        # 이벤트/논이벤트 분리 후 논이벤트에 대한 층화추출을 수행\n",
    "        df_smpl_tmp_2_n = (\n",
    "            df_smpl_tmp_1[df_smpl_tmp_1['공포_타겟'] != 1]\n",
    "            .groupby(['성별', '연령대'])\n",
    "            .sample(\n",
    "                frac         = event_rt * i_smpl_rt\n",
    "                , random_state = 0\n",
    "                , replace      = True # True - 복원추출 / False - 비복원추출 \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 샘플링 배수 컬럼 추가 \n",
    "        df_smpl_tmp_2_n['샘플링배수'] = i_smpl_rt\n",
    "        \n",
    "        # 전체 이벤트 고객 추출 \n",
    "        df_smpl_tmp_2_y = df_smpl_tmp_1[df_smpl_tmp_1['공포_타겟'] == 1].copy()\n",
    "        \n",
    "        # 샘플링 배수 컬럼 추가\n",
    "        df_smpl_tmp_2_y['샘플링배수'] = i_smpl_rt\n",
    "        \n",
    "        # 데이터 통합\n",
    "        df_smpl_tmp = pd.concat([df_smpl_tmp_2_n, df_smpl_tmp_2_y], ignore_index = True)\n",
    "        \n",
    "        # 데이터 Append\n",
    "        list_df_smpl.append(df_smpl_tmp)\n",
    "\n",
    "df_smpl = pd.concat(list_df_smpl)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "# 2. 학습마트 전처리\n",
    "#######################################################################################\n",
    "#################################################################\n",
    "# 2-1. 피쳐마트 로드 및 결합\n",
    "#################################################################\n",
    "# 피쳐마트 로드\n",
    "df_ftr_mart = pd.read_sql(f\"\"\"\n",
    "    SELECT\n",
    "          *\n",
    "    FROM INPUT_MART\n",
    "    WHERE 기준년월 BETWEEN {min(list_bas_ym)} and {max(list_bas_ym)}\n",
    "\"\"\", conn)\n",
    "\n",
    "df_mart_base = pd.merge(df_smpl[['기준년월', '회원번호', '샘플링배수', '공포_타겟']], df_ftr_mart, on = ['기준년월', '회원번호'], how = 'left')\n",
    "\n",
    "#################################################################\n",
    "# 2-2. 결측 처리\n",
    "#################################################################\n",
    "list_pk = ['기준년월', '회원번호', '샘플링배수', '공포_타겟']\n",
    "\n",
    "# 변수 리스트 생성\n",
    "df_var_list = pd.DataFrame(df_mart_base.dtypes, columns = [\"변수유형\"]).reset_index().rename(columns = {\"index\" : \"변수명\"})\n",
    "\n",
    "# 연속형 변수 리스트 생성\n",
    "df_num_list = (\n",
    "    df_var_list[\n",
    "            (df_var_list[\"변수유형\"] != 'object')\n",
    "            & ~(df_var_list[\"변수명\"].isin(list_pk))\n",
    "    ]\n",
    ")    \n",
    "        \n",
    "# 범주형 변수 리스트 생성\n",
    "df_char_list = (\n",
    "    df_var_list[\n",
    "            (df_var_list[\"변수유형\"] == 'object')\n",
    "        & ~(df_var_list[\"변수명\"].isin(list_pk))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 연속형 변수 결측값에 대해 일괄적으로 0으로 대체, 범주형 변수 결측값에 대해 일괄적으로 '기타'로 대체\n",
    "df_mart_1 = df_mart_base.copy()\n",
    "df_mart_1[df_num_list[\"변수명\"]]  = df_mart_1[df_num_list[\"변수명\"] ].fillna(0)\n",
    "df_mart_1[df_char_list[\"변수명\"]] = df_mart_1[df_char_list[\"변수명\"]].fillna('기타')\n",
    "\n",
    "#################################################################\n",
    "# 2-3. OneHotEncoding\n",
    "#################################################################\n",
    "# 원핫인코딩 적합\n",
    "oneHotEncdr = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore').fit(df_mart_1[df_char_list[\"변수명\"]])\n",
    "\n",
    "# 원핫인코딩 적용\n",
    "tmp_cat = pd.DataFrame(\n",
    "    oneHotEncdr.transform(df_mart_1[df_char_list[\"변수명\"]]),\n",
    "    columns=[x.replace(\" \", \"\") for x in oneHotEncdr.get_feature_names_out(df_char_list[\"변수명\"])]\n",
    ")\n",
    "\n",
    "# 데이터프레임 초기화\n",
    "df_onehot_encdr = pd.DataFrame(columns=['변수명', '변수개수', '처리방법'])\n",
    "\n",
    "# 속성값 개수와 처리방법 저장\n",
    "for v_onehot in df_char_list['변수명']:\n",
    "    v_col_cnt = df_mart_1[v_onehot].nunique()\n",
    "    df_onehot_encdr = pd.concat([df_onehot_encdr, pd.DataFrame({\n",
    "        '변수명': [v_onehot],\n",
    "        '변수개수': [v_col_cnt],\n",
    "        '처리방법': ['원핫인코딩']\n",
    "    })], ignore_index=True)\n",
    "\n",
    "# 원핫인코딩 정보로 대체\n",
    "df_mart_2 = df_mart_1[df_mart_1.columns[~df_mart_1.columns.isin(df_char_list[\"변수명\"])]]\n",
    "\n",
    "df_mart_2 = pd.concat(\n",
    "    [df_mart_1[df_mart_1.columns[~df_mart_1.columns.isin(list_pk)]], tmp_cat],\n",
    "        axis=1\n",
    ")\n",
    "\n",
    "with open(f\"{dir_mdl}/oneHotEncoder_horror.pkl\", \"wb\") as f: \n",
    "    dump(oneHotEncdr, f)\n",
    "\n",
    "# encoder = load(open(f'{dir_mdl}/oneHotEncoder_horror.pkl', 'rb'))\n",
    "df_train = pd.concat(\n",
    "    [ df_mart_1[list_pk], df_mart_2],\n",
    "        axis=1\n",
    ")\n",
    "df_train.to_pickle(f\"{dir_mdl}/df_horror_input.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 샘플링배수 = 1 | Train 데이터 길이 : 4317\n",
      "[LOG] 샘플링배수 = 1 | valid 데이터 길이 : 1080\n",
      "[LOG] 샘플링배수 = 2 | Train 데이터 길이 : 6476\n",
      "[LOG] 샘플링배수 = 2 | valid 데이터 길이 : 1619\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# 3. 모형 생성\n",
    "#######################################################################################\n",
    "#################################################################\n",
    "# 3-1-1. 1차 모형 생성\n",
    "#################################################################\n",
    "list_df_valid_prfmnc = []\n",
    "for i, x_smpl_ratio in enumerate([1,2]) :\n",
    "    \n",
    "    df_train_tmp = df_train[df_train['샘플링배수'] == x_smpl_ratio]\n",
    "    # Train / Valid 분할\n",
    "    df_X_train, df_X_valid, df_Y_train, df_Y_valid = \\\n",
    "        train_test_split(df_train_tmp[df_train_tmp.columns[~df_train_tmp.columns.isin(list_pk)]], df_train_tmp['공포_타겟'], test_size = 0.2, random_state = 0)\n",
    "\n",
    "    print(f\"\"\"[LOG] 샘플링배수 = {x_smpl_ratio} | Train 데이터 길이 : {len(df_X_train)}\"\"\")\n",
    "    print(f\"\"\"[LOG] 샘플링배수 = {x_smpl_ratio} | valid 데이터 길이 : {len(df_X_valid)}\"\"\")\n",
    "    \n",
    "    # 랜덤포레스트\n",
    "    mdl_rf = RandomForestClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "    mdl_rf.fit(df_X_train, df_Y_train)\n",
    "    dump(mdl_rf, open(f'{dir_mdl}/mdl_1st_horror_smpl_{x_smpl_ratio}_rf.pkl', 'wb'))\n",
    "    \n",
    "     # XGBOOST모델 학습 및 저장\n",
    "    mdl_xgb  = XGBClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "    mdl_xgb.fit(df_X_train, df_Y_train)\n",
    "    dump(mdl_xgb, open(f'{dir_mdl}/mdl_1st_horror_smpl_{x_smpl_ratio}_xgb.pkl', 'wb'))\n",
    "\n",
    "    # LIGHTGBM모델 학습 및 저장\n",
    "    mdl_lgb  = LGBMClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "    mdl_lgb.fit(df_X_train, df_Y_train)\n",
    "    dump(mdl_lgb, open(f'{dir_mdl}/mdl_1st_horror_smpl_{x_smpl_ratio}_lgb.pkl', 'wb'))\n",
    "\n",
    "    # RF모델 학습결과 생성\n",
    "    df_Y_valid_rf          = pd.concat([df_Y_valid.reset_index(drop = True), pd.Series([x[1] for x in mdl_rf.predict_proba(df_X_valid)])], axis = 1)\n",
    "    df_Y_valid_rf.columns  = ['Y_Real', 'Y_Prob'] \n",
    "\n",
    "    # xgboost모델 학습결과 생성\n",
    "    df_Y_valid_xgb         = pd.concat([df_Y_valid.reset_index(drop = True), pd.Series([x[1] for x in mdl_xgb.predict_proba(df_X_valid)])], axis = 1)\n",
    "    df_Y_valid_xgb.columns = ['Y_Real', 'Y_Prob'] \n",
    "\n",
    "    # lightgbm모델 학습결과 생성\n",
    "    df_Y_valid_lgb         = pd.concat([df_Y_valid.reset_index(drop = True), pd.Series([x[1] for x in mdl_lgb.predict_proba(df_X_valid)])], axis = 1)\n",
    "    df_Y_valid_lgb.columns = ['Y_Real', 'Y_Prob']\n",
    "    \n",
    "    # 검증 데이터셋 성능 지표 산출\n",
    "    df_valid_prfmnc_rf  = func_mdl_prfmnc(df_Y_valid_rf )\n",
    "    df_valid_prfmnc_xgb = func_mdl_prfmnc(df_Y_valid_xgb)\n",
    "    df_valid_prfmnc_lgb = func_mdl_prfmnc(df_Y_valid_lgb)\n",
    "    \n",
    "    df_valid_prfmnc_rf['샘플링배수']  = x_smpl_ratio\n",
    "    df_valid_prfmnc_rf['알고리즘명']  = 'rf'\n",
    "    df_valid_prfmnc_xgb['샘플링배수'] = x_smpl_ratio\n",
    "    df_valid_prfmnc_xgb['알고리즘명'] = 'xgb'\n",
    "    df_valid_prfmnc_lgb['샘플링배수'] = x_smpl_ratio\n",
    "    df_valid_prfmnc_lgb['알고리즘명'] = 'lgb'\n",
    "    \n",
    "    list_df_valid_prfmnc.append(df_valid_prfmnc_rf )\n",
    "    list_df_valid_prfmnc.append(df_valid_prfmnc_xgb)\n",
    "    list_df_valid_prfmnc.append(df_valid_prfmnc_lgb)\n",
    "    \n",
    "    \n",
    "# 성능 지표 결과 통합\n",
    "df_valid_prfmnc = pd.concat(list_df_valid_prfmnc)[['샘플링배수', '알고리즘명','cutoff', 'R1', 'P1', 'RP11', 'RP10', 'RP01', 'RP00', 'precision', 'recall', 'f1score',]]\n",
    "\n",
    "# 1차 모델 최적 샘플배수 및 알고리즘 추출\n",
    "v_best_smpl = df_valid_prfmnc[df_valid_prfmnc['f1score'] == df_valid_prfmnc['f1score'].max()]['샘플링배수'].values[0]\n",
    "v_best_algo = df_valid_prfmnc[df_valid_prfmnc['f1score'] == df_valid_prfmnc['f1score'].max()]['알고리즘명'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 샘플배수 = 1 | 알고리즘 = rf\n",
      "[LOG] 샘플배수 = 1 | 알고리즘 = xgb\n",
      "[LOG] 샘플배수 = 1 | 알고리즘 = lgb\n",
      "[LOG] 샘플배수 = 2 | 알고리즘 = rf\n",
      "[LOG] 샘플배수 = 2 | 알고리즘 = xgb\n",
      "[LOG] 샘플배수 = 2 | 알고리즘 = lgb\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# 3-1-2. 1차 모형 테스트\n",
    "#################################################################\n",
    "#########################################\n",
    "# 테스트마트 생성\n",
    "#########################################\n",
    "df_test = pd.read_sql(f\"\"\"\n",
    "    SELECT \n",
    "          T1.*\n",
    "        , ifnull(T2.공포_타겟, 0)                                   as 공포_타겟\n",
    "    FROM INPUT_MART T1\n",
    "    LEFT JOIN TARGET_MART T2\n",
    "    ON \n",
    "        T1.기준년월 = T2.기준년월\n",
    "    AND T1.회원번호 = T2.회원번호\n",
    "    WHERE T1.기준년월 = {bas_ym_aft_1m}\n",
    "\"\"\", conn)\n",
    "\n",
    "#########################################\n",
    "# 결측 처리\n",
    "#########################################\n",
    "list_pk = ['기준년월', '회원번호', '샘플링배수', '공포_타겟']\n",
    "\n",
    "# 변수 리스트 생성\n",
    "df_var_list = pd.DataFrame(df_test.dtypes, columns = [\"변수유형\"]).reset_index().rename(columns = {\"index\" : \"변수명\"})\n",
    "\n",
    "# 연속형 변수 리스트 생성\n",
    "df_num_list = (\n",
    "    df_var_list[\n",
    "            (df_var_list[\"변수유형\"] != 'object')\n",
    "            & ~(df_var_list[\"변수명\"].isin(list_pk))\n",
    "    ]\n",
    ")    \n",
    "        \n",
    "# 범주형 변수 리스트 생성\n",
    "df_char_list = (\n",
    "    df_var_list[\n",
    "            (df_var_list[\"변수유형\"] == 'object')\n",
    "        & ~(df_var_list[\"변수명\"].isin(list_pk))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 연속형 변수 결측값에 대해 일괄적으로 0으로 대체, 범주형 변수 결측값에 대해 일괄적으로 '기타'로 대체\n",
    "df_test_mart_1 = df_test.copy()\n",
    "df_test_mart_1[df_num_list[\"변수명\"]]  = df_test_mart_1[df_num_list[\"변수명\"] ].fillna(0)\n",
    "df_test_mart_1[df_char_list[\"변수명\"]] = df_test_mart_1[df_char_list[\"변수명\"]].fillna('기타')\n",
    "\n",
    "#########################################\n",
    "# OneHotEncoding\n",
    "#########################################\n",
    "# 원핫인코더 로드\n",
    "oneHotEncdr = load(open(f\"{dir_mdl}/oneHotEncoder_horror.pkl\", 'rb'))\n",
    "\n",
    "# 원핫인코딩 적용\n",
    "tmp_cat = pd.DataFrame(\n",
    "    oneHotEncdr.transform(df_test_mart_1[df_char_list[\"변수명\"]]),\n",
    "    columns=[x.replace(\" \", \"\") for x in oneHotEncdr.get_feature_names_out(df_char_list[\"변수명\"])]\n",
    ")\n",
    "if len(tmp_cat.columns) > 0 : \n",
    "    df_test_mart_2 = pd.concat(\n",
    "        [df_test_mart_1[df_test_mart_1[df_test_mart_1.columns[~df_test_mart_1.columns.isin(df_char_list['변수명'].to_list())]].reset_index(drop=True), tmp_cat.reset_index(drop=True)]]\n",
    "    )\n",
    "else : \n",
    "    df_test_mart_2 = df_test_mart_1.copy()\n",
    "    \n",
    "#########################################\n",
    "# 1차 모형 테스트 시작\n",
    "#########################################\n",
    "# 테스트마트 데이터를 X와 Y로 분리\n",
    "df_test_1st_X = df_test_mart_2.drop(columns = ['기준년월', '회원번호', '공포_타겟'])\n",
    "df_test_1st_Y = df_test_mart_2['공포_타겟'].astype(int)\n",
    "\n",
    "list_df_test_prfmnc = []\n",
    "for i, smpl_ratio in enumerate([1,2]) :\n",
    "    for i, algo in enumerate(['rf', 'xgb', 'lgb']) :\n",
    "        print(f'[LOG] 샘플배수 = {smpl_ratio} | 알고리즘 = {algo}')\n",
    "        mdl = pd.read_pickle(f'{dir_mdl}/mdl_1st_horror_smpl_{smpl_ratio}_{algo}.pkl')\n",
    "        df_test_scr =  pd.concat([df_test_1st_Y.reset_index(drop = True), pd.Series([x[1] for x in mdl .predict_proba(df_test_1st_X)])], axis = 1)\n",
    "        df_test_scr.columns = ['Y_Real', 'Y_Prob']\n",
    "        \n",
    "        # 테스트 성능 지표 산출\n",
    "        df_test_1st_prfmnc_tmp  = func_mdl_prfmnc(df_test_scr)\n",
    "        \n",
    "        # 모형 라벨링 정보 추가\n",
    "        df_test_1st_prfmnc_tmp['알고리즘명'] = algo\n",
    "        df_test_1st_prfmnc_tmp['샘플링배수'] = smpl_ratio\n",
    "\n",
    "        list_df_test_prfmnc.append(df_test_1st_prfmnc_tmp)\n",
    "\n",
    "# 성능 지표 결과 통합\n",
    "df_test_1st_prfmnc = pd.concat(list_df_test_prfmnc)[['샘플링배수','알고리즘명','cutoff', 'R1', 'P1', 'RP11', 'RP10', 'RP01', 'RP00', 'precision', 'recall', 'f1score',]]\n",
    "\n",
    "# 1차 모형 테스트셋 최적 알고리즘 추출\n",
    "v_test_best_algo = df_test_1st_prfmnc[df_test_1st_prfmnc['f1score'] == df_test_1st_prfmnc['f1score'].max()]['알고리즘명'].values[0]\n",
    "v_test_best_smpl = df_test_1st_prfmnc[df_test_1st_prfmnc['f1score'] == df_test_1st_prfmnc['f1score'].max()]['샘플링배수'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 0 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 10 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 20 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 30 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 40 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 50 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 60 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 70 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 80 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 90 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 100 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 110 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 120 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 130 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 140 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 150 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 160 / 180\n",
      "[LOG] func_mdl_pre_iv > 연속형 변수 Binning : 170 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 0 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 10 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 20 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 30 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 40 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 50 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 60 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 70 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 80 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 90 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 100 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 110 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 120 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 130 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 140 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 150 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 160 / 180\n",
      "[LOG] func_mdl_pre_iv > IV 산출 : 170 / 180\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# 3-2-1. 변수선택\n",
    "#################################################################\n",
    "# IV WOE 산출을 위한 입력마트 생성\n",
    "df_iv_base = pd.read_sql(f\"\"\" \n",
    "    SELECT \n",
    "          T1.*\n",
    "        , IFNULL(T2.공포_타겟, 0)                   AS 공포_타겟\n",
    "    FROM INPUT_MART T1\n",
    "    \n",
    "    LEFT JOIN TARGET_MART T2\n",
    "    ON \n",
    "        T1.기준년월 = T2.기준년월\n",
    "    AND T1.회원번호 = T2.회원번호\n",
    "    \n",
    "    WHERE T1.기준년월 BETWEEN {min(list_bas_ym)} and {max(list_bas_ym)}\n",
    "\"\"\", conn)\n",
    "\n",
    "df_iv_base = df_iv_base.rename(columns = {'공포_타겟' : 'y'})\n",
    "df_iv_res = func_mdl_iv_woe(df_iv_base,  ['기준년월', '회원번호', 'y'])\n",
    "\n",
    "# 1차 채택 모형의 변수중요도 추출\n",
    "mdl_best_algo_1st = pd.read_pickle(f'{dir_mdl}/mdl_1st_horror_smpl_{v_test_best_smpl}_{v_test_best_algo}.pkl')  \n",
    "df_ftr_imp = pd.DataFrame({\n",
    "      'varNm'       : mdl_best_algo_1st.feature_names_in_\n",
    "    # , 'algorithm' : 'rf'\n",
    "    , '변수중요도'    : mdl_best_algo_1st.feature_importances_/mdl_best_algo_1st.feature_importances_.sum()\n",
    "}).sort_values(['변수중요도'], ascending = False)\n",
    "\n",
    "# 영향인자분석 결과 통합\n",
    "df_factor = pd.merge(df_ftr_imp, df_iv_res.groupby(['varNm']).max()['iv_sum'].round(5).reset_index(), on = 'varNm', how = 'left')\n",
    "\n",
    "###############################################\n",
    "# 영향인자분석 결과를 반영한 변수선택 결과 추출 \n",
    "#  - IV 상위 60% \n",
    "#  - 연관장르\n",
    "###############################################\n",
    "# IV 상위 추출\n",
    "df_ftr_selection = df_factor.sort_values(by = ['iv_sum'], ascending = False)[:int(len(df_factor) * 0.6)]\n",
    "\n",
    "# 연관장르만 추출\n",
    "list_unrelated_genre = ['드라마' ,'코미디' ,'전쟁' ,'로맨스' ,'가족' ,'애니메이션' ,'스포츠' ,'전기' ,'뮤지컬' ,'음악' ,'단편극' ,'역사' ,'서부극' ,'다큐멘터리']\n",
    "list_ftr_selection_2 = [x for x in df_ftr_selection['varNm'].to_list() \n",
    "    if   any(key in x for key in list_unrelated_genre)  # 비연관 장르 제외\n",
    "      or ('최근' not in x)                              # 행동정보 이외 컬럼 \n",
    "]\n",
    "list_ftr_selection = df_ftr_selection[df_ftr_selection['varNm'].isin(list_ftr_selection_2)]['varNm'].to_list()\n",
    "\n",
    "# 변수선택 결과 저장\n",
    "with open(f'{dir_mdl}/list_horror_ftr_selection.pkl', 'wb') as f:\n",
    "    dump(list_ftr_selection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 2차 모형 학습 | 최적알고리즘 = rf |\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# 3-3-1. 2차 모형 생성\n",
    "#################################################################\n",
    "# 2차모형 조건 추출\n",
    "#  - v_test_best_algo  #최적알고리즘\n",
    "#  - v_test_best_smpl  #최적샘플배수\n",
    "#  - list_ftr_selection #변수선택결과\n",
    "\n",
    "# 학습 데이터 로드 및 조건반영\n",
    "df_train_2nd = df_train[(df_train['샘플링배수'] == v_test_best_smpl)][list_pk + list_ftr_selection]\n",
    "list_pk = ['기준년월', '회원번호', '공포_타겟']\n",
    "\n",
    "#########################################\n",
    "# 2차 모형 학습\n",
    "#########################################\n",
    "# Train / Valid 분할\n",
    "df_X_train, df_X_valid, df_Y_train, df_Y_valid = \\\n",
    "    train_test_split(df_train_2nd[df_train_2nd.columns[~df_train_2nd.columns.isin(list_pk)]], df_train_2nd['공포_타겟'], test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(f'[LOG] 2차 모형 학습 | 최적알고리즘 = {v_test_best_algo} |')\n",
    "\n",
    "if v_test_best_algo == 'rf' :\n",
    "    mdl_2nd = RandomForestClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "elif v_test_best_algo == 'xgb' :\n",
    "    mdl_2nd = XGBClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "elif v_test_best_algo == 'lgb' :\n",
    "    mdl_2nd = LGBMClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "   \n",
    "mdl_2nd.fit(df_X_train, df_Y_train)\n",
    "dump(mdl_2nd, open(f'{dir_mdl}/mdl_horror_smpl_{v_test_best_smpl}_{v_test_best_algo}_2nd.pkl', 'wb'))\n",
    "\n",
    "# 모형 검증\n",
    "df_Y_valid          = pd.concat([df_Y_valid.reset_index(drop = True), pd.Series([x[1] for x in mdl_2nd.predict_proba(df_X_valid)])], axis = 1)\n",
    "df_Y_valid.columns  = ['Y_Real', 'Y_Prob'] \n",
    "df_valid_prfmnc_2nd = func_mdl_prfmnc(df_Y_valid_rf)\n",
    "\n",
    "#########################################\n",
    "# 2차 모형 테스트 시작\n",
    "#########################################\n",
    "# 테스트마트 데이터를 X와 Y로 분리\n",
    "df_test_2nd_X = df_test_1st_X.copy()[list_ftr_selection]\n",
    "df_test_2nd_Y = df_test_1st_Y.copy()\n",
    "\n",
    "# 2차 모형 테스트 스코어 산출\n",
    "df_test_2nd_scr =  pd.concat([df_test_2nd_Y.reset_index(drop = True), pd.Series([x[1] for x in mdl_2nd.predict_proba(df_test_2nd_X)])], axis = 1)\n",
    "df_test_2nd_scr.columns = ['Y_Real', 'Y_Prob']\n",
    "\n",
    "# 2차 모형 테스트 성능 지표 산출\n",
    "df_test_2nd_prfmnc  = func_mdl_prfmnc(df_test_2nd_scr)\n",
    "\n",
    "# 1차 2차 성능 비교\n",
    "df_1st = df_test_1st_prfmnc[df_test_1st_prfmnc['f1score'] == df_test_1st_prfmnc[(df_test_1st_prfmnc['알고리즘명'] == v_best_algo) & (df_test_1st_prfmnc['샘플링배수'] == v_best_smpl)]['f1score'].max()].drop(columns=['샘플링배수', '알고리즘명'])\n",
    "df_2nd = df_test_2nd_prfmnc[df_test_2nd_prfmnc['f1score'] == df_test_2nd_prfmnc['f1score'].max()]\n",
    "df_1st['모형구분'] = '1차결과'\n",
    "df_2nd['모형구분'] = '2차결과'\n",
    "df_1st_2nd_comparison = pd.concat([df_1st, df_2nd])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 파생변수 생성\n",
    "#########################################\n",
    "list_drv_bas_ym = [datetime.strftime(datetime.strptime(bas_ym, '%Y%m') - relativedelta(months = (i-1) ), '%Y%m') for i in range(4)]\n",
    "list_df_drv_ftr = []\n",
    "\n",
    "# 최근 3개월, 6개월 간 연관 장르 행동정보 추가\n",
    "for i, x_bas_ym in enumerate(list_drv_bas_ym) :\n",
    "  x_bas_ym_bfr_2m = datetime.strftime(datetime.strptime(x_bas_ym, '%Y%m') - relativedelta(months = 2 ), '%Y%m')\n",
    "  x_bas_ym_bfr_5m = datetime.strftime(datetime.strptime(x_bas_ym, '%Y%m') - relativedelta(months = 5 ), '%Y%m')\n",
    "\n",
    "  df_drv_ftr_tmp = pd.read_sql(f\"\"\"\n",
    "    select\n",
    "          {x_bas_ym}                                                                                                           as 기준년월\n",
    "        , T1.회원번호\n",
    "\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  7      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_액션_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  7      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_액션_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  7      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_액션_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  7      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_액션_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  7      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_액션_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  9      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_스릴러_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  9      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_스릴러_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  9      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_스릴러_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  9      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_스릴러_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  9      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_스릴러_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 45      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_공상과학_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 45      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_공상과학_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 45      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_공상과학_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 45      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_공상과학_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 45      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_공상과학_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  8      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_범죄_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  8      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_범죄_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  8      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_범죄_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  8      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_범죄_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 =  8      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_범죄_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 12      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_판타지_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 12      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_판타지_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 12      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_판타지_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 12      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_판타지_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 12      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_판타지_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 11      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_모험_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 11      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_모험_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 11      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_모험_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 11      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_모험_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 11      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_모험_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 20      and T2.행동번호 = 5         then 1 else 0 end)         as 최근6개월_미스테리_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 20      and T2.행동번호 = 1         then 1 else 0 end)         as 최근6개월_미스테리_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 20      and T2.행동번호 = 2         then 1 else 0 end)         as 최근6개월_미스테리_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 20      and T2.행동번호 = 4         then 1 else 0 end)         as 최근6개월_미스테리_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근6개월' and  T2.장르번호 = 20      and T2.행동번호 = 11        then 1 else 0 end)         as 최근6개월_미스테리_구매횟수\n",
    "        \n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  7      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_액션_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  7      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_액션_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  7      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_액션_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  7      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_액션_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  7      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_액션_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  9      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_스릴러_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  9      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_스릴러_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  9      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_스릴러_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  9      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_스릴러_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  9      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_스릴러_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 45      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_공상과학_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 45      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_공상과학_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 45      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_공상과학_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 45      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_공상과학_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 45      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_공상과학_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  8      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_범죄_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  8      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_범죄_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  8      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_범죄_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  8      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_범죄_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 =  8      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_범죄_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 12      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_판타지_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 12      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_판타지_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 12      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_판타지_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 12      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_판타지_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 12      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_판타지_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 11      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_모험_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 11      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_모험_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 11      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_모험_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 11      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_모험_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 11      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_모험_구매횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 20      and T2.행동번호 = 5         then 1 else 0 end)         as 최근3개월_미스테리_탐색횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 20      and T2.행동번호 = 1         then 1 else 0 end)         as 최근3개월_미스테리_평가횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 20      and T2.행동번호 = 2         then 1 else 0 end)         as 최근3개월_미스테리_시청완료횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 20      and T2.행동번호 = 4         then 1 else 0 end)         as 최근3개월_미스테리_시청시작횟수\n",
    "        , sum(case WHEN T2.기간 = '최근3개월' and  T2.장르번호 = 20      and T2.행동번호 = 11        then 1 else 0 end)         as 최근3개월_미스테리_구매횟수\n",
    "\n",
    "    -- 대상 고객 : 최근 3개월 활성고객\n",
    "    FROM (\n",
    "        SELECT\n",
    "                회원번호\n",
    "        FROM MOVIE_FACT\n",
    "        WHERE 기준년월 BETWEEN {x_bas_ym_bfr_2m} and {x_bas_ym}\n",
    "        GROUP BY 회원번호\n",
    "    ) T1\n",
    "\n",
    "    LEFT JOIN (\n",
    "        SELECT\n",
    "              기준년월 \n",
    "            , CASE WHEN a01.기준년월 BETWEEN {x_bas_ym_bfr_2m} and {x_bas_ym}            then  '최근3개월'\n",
    "                  ELSE                                                                         '최근6개월'\n",
    "              END                                                                                       as 기간\n",
    "            , a01.회원번호\n",
    "            , a02.장르번호\n",
    "            , a01.행동번호\n",
    "        FROM MOVIE_FACT a01\n",
    "\n",
    "        ----------------------------------------------------------------\n",
    "        -- 장르 매핑\n",
    "        ----------------------------------------------------------------\n",
    "        LEFT JOIN (\n",
    "            SELECT\n",
    "                  영화번호\n",
    "                , 장르번호\n",
    "            FROM MOVIE_GENRE\n",
    "\n",
    "            --------------------------------------------\n",
    "            -- 중복 장르 번호 제거\n",
    "            --------------------------------------------\n",
    "            EXCEPT\n",
    "            SELECT\n",
    "                  b01.영화번호\n",
    "                , b02.장르번호\n",
    "            FROM MOVIE b01\n",
    "\n",
    "            LEFT JOIN MOVIE_GENRE b02 -- 영화 장르 매핑\n",
    "            ON b01.영화번호 = b02.영화번호\n",
    "\n",
    "            LEFT JOIN GENRE b03 -- 장르명 매핑\n",
    "            ON b02.장르번호 = b03.장르번호\n",
    "\n",
    "            GROUP BY\n",
    "                  b01.영화번호\n",
    "                , b03.장르명\n",
    "            HAVING COUNT(1) > 1  -- 중복 존재 장르번호 추출\n",
    "        ) a02\n",
    "        ON a01.영화번호 = a02.영화번호\n",
    "\n",
    "        WHERE a01.기준년월 BETWEEN {x_bas_ym_bfr_5m} and {bas_ym}\n",
    "        GROUP BY \n",
    "            a01.기준년월\n",
    "          , a01.회원번호\n",
    "          , a02.장르번호\n",
    "          , a01.행동번호\n",
    "    ) T2\n",
    "    ON T1.회원번호 = T2.회원번호\n",
    "\n",
    "    group by t1.회원번호\n",
    "  \"\"\"\n",
    "  , conn)\n",
    "  \n",
    "  list_df_drv_ftr.append(df_drv_ftr_tmp)\n",
    "\n",
    "df_drv_ftr = pd.concat(list_df_drv_ftr)\n",
    "df_train_3rd = pd.merge(df_train_2nd, df_drv_ftr, on = ['기준년월', '회원번호'], how = 'left' ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 3차 모형 학습 | 최적알고리즘 = rf |\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 3차 모형 학습\n",
    "#########################################\n",
    "# Train / Valid 분할\n",
    "df_X_train = df_train_3rd[df_train_3rd.columns[~df_train_3rd.columns.isin(list_pk)]]\n",
    "df_Y_train = df_train_3rd['공포_타겟']\n",
    "\n",
    "print(f'[LOG] 3차 모형 학습 | 최적알고리즘 = {v_test_best_algo} |')\n",
    "\n",
    "if v_test_best_algo == 'rf' :\n",
    "    mdl_3rd = RandomForestClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "elif v_test_best_algo == 'xgb' :\n",
    "    mdl_3rd = XGBClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "elif v_test_best_algo == 'lgb' :\n",
    "    mdl_3rd = LGBMClassifier(n_estimators = 100, max_depth = 10, random_state=0, verbose = 0)\n",
    "\n",
    "mdl_3rd.fit(df_X_train, df_Y_train)\n",
    "dump(mdl_3rd, open(f'{dir_mdl}/mdl_3rd_horror_smpl_{v_test_best_smpl}_{v_test_best_algo}.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff</th>\n",
       "      <th>R1</th>\n",
       "      <th>P1</th>\n",
       "      <th>RP11</th>\n",
       "      <th>RP10</th>\n",
       "      <th>RP01</th>\n",
       "      <th>RP00</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>모형구분</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>884</td>\n",
       "      <td>973</td>\n",
       "      <td>1712</td>\n",
       "      <td>169</td>\n",
       "      <td>80</td>\n",
       "      <td>804</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.910154</td>\n",
       "      <td>0.932208</td>\n",
       "      <td>2차결과</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>884</td>\n",
       "      <td>979</td>\n",
       "      <td>1718</td>\n",
       "      <td>163</td>\n",
       "      <td>68</td>\n",
       "      <td>816</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>0.913344</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>3차결과</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cutoff   R1   P1  RP11  RP10  RP01  RP00  precision    recall   f1score  \\\n",
       "0      54  884  973  1712   169    80   804   0.955357  0.910154  0.932208   \n",
       "0      47  884  979  1718   163    68   816   0.961926  0.913344  0.937006   \n",
       "\n",
       "   모형구분  \n",
       "0  2차결과  \n",
       "0  3차결과  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################\n",
    "# 3차 모형 테스트 시작\n",
    "#########################################\n",
    "# 테스트마트 데이터를 X와 Y로 분리\n",
    "df_test_3rd = pd.merge(df_test_mart_2[list_pk + list_ftr_selection], df_drv_ftr, on = ['기준년월', '회원번호'], how = 'left')\n",
    "df_test_3rd_X = df_test_3rd[df_test_3rd.columns[~df_test_3rd.columns.isin(list_pk)]]\n",
    "df_test_3rd_Y = df_test_3rd['공포_타겟']\n",
    "\n",
    "# 3차 모형 테스트 스코어 산출\n",
    "df_test_3rd_scr =  pd.concat([df_test_3rd_Y.reset_index(drop = True), pd.Series([x[1] for x in mdl_3rd.predict_proba(df_test_3rd_X)])], axis = 1)\n",
    "df_test_3rd_scr.columns = ['Y_Real', 'Y_Prob']\n",
    "\n",
    "# 2차 모형 테스트 성능 지표 산출\n",
    "df_test_3rd_prfmnc  = func_mdl_prfmnc(df_test_3rd_scr)\n",
    "\n",
    "# 1차 2차 성능 비교\n",
    "df_2nd = df_test_2nd_prfmnc[df_test_2nd_prfmnc['f1score'] == df_test_2nd_prfmnc['f1score'].max()]\n",
    "df_3rd = df_test_3rd_prfmnc[df_test_3rd_prfmnc['f1score'] == df_test_3rd_prfmnc['f1score'].max()]\n",
    "df_2nd['모형구분'] = '2차결과'\n",
    "df_3rd['모형구분'] = '3차결과'\n",
    "df_2nd_3rd_comparison = pd.concat([df_2nd, df_3rd])\n",
    "\n",
    "display(df_2nd_3rd_comparison)\n",
    "\n",
    "#########################################\n",
    "# 챔피언 모형 선정 및 저장\n",
    "#########################################\n",
    "chmp_mdl    = mdl_3rd if df_test_2nd_prfmnc['f1score'].max() < df_test_3rd_prfmnc['f1score'].max() else mdl_2nd\n",
    "chmp_prfmnc = df_test_3rd_prfmnc if df_test_2nd_prfmnc['f1score'].max() < df_test_3rd_prfmnc['f1score'].max() else df_test_2nd_prfmnc\n",
    "with open(f\"{dir_prd}/mdl_horror.pkl\", \"wb\") as f: \n",
    "    dump(chmp_mdl, f)\n",
    "with open(f\"{dir_prd}/df_prfmnc.pkl\", \"wb\") as f: \n",
    "    dump(chmp_prfmnc, f)\n",
    "    \n",
    "# 최종 변수 리스트 저장\n",
    "list_ftr_fin = list_ftr_selection + [x for x in df_drv_ftr.columns.tolist() if x not in list_pk]\n",
    "with open(f\"{dir_prd}/list_horror_ftr.pkl\", \"wb\") as f: \n",
    "    dump(list_ftr_fin, f)\n",
    "    \n",
    "# 원핫인코더 운영 경로 저장\n",
    "with open(f\"{dir_prd}/oneHotEncoder_horror.pkl\", \"wb\") as f: \n",
    "    dump(oneHotEncdr, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
